{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63ec7163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# book_dim\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_storage\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import normalize\n",
    "# Custom Functions\n",
    "from gcp_getsecrets import get_gcp_secret\n",
    "from gcp_postbucket import save_bucket\n",
    "from gcp_getbucket import get_bucket_csv\n",
    "from gcp_getbigquery import read_bq_table\n",
    "from gcp_savebigquery import save_to_bq\n",
    "\n",
    "#ARCHIVE PATH\n",
    "archive_path = r'D:\\\\BleakRiverDataServ\\\\Clients\\\\Button\\\\RoyaltyCheck\\\\'\n",
    "# Define project\n",
    "project_id = f\"button-datawarehouse\"\n",
    "# Define storage bucket for push\n",
    "bucket_name = \"cs-royalties-test\"  # Replace with your bucket name\n",
    "# Scopes for Service Account\n",
    "SCOPES = [\n",
    "    \"https://www.googleapis.com/auth/drive\",\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "    \"https://www.googleapis.com/auth/admin.datatransfer\",\n",
    "    \"https://www.googleapis.com/auth/bigquery\",\n",
    "    \"https://www.googleapis.com/auth/cloud-platform\"\n",
    "]\n",
    "# Define secrets to fetch\n",
    "p_consumerkey = get_gcp_secret(project_id, \"wc_consumer_key\", \"latest\")\n",
    "p_consumersecret = get_gcp_secret(project_id, \"wc_consumer_secret\", \"latest\")\n",
    "secret_id_for_sa_key = \"storage_sa_key\" # The secret you just created\n",
    "# get those secrets\n",
    "sa_key_json_string = get_gcp_secret(project_id, secret_id_for_sa_key)\n",
    "credentials_info = json.loads(sa_key_json_string)\n",
    "credentials = service_account.Credentials.from_service_account_info(credentials_info, scopes = SCOPES)\n",
    "storage_client = storage.Client(credentials=credentials, project=project_id)\n",
    "bq_client = bigquery.Client(credentials=credentials)\n",
    "\n",
    "\"\"\" \n",
    "0. BOOKS_INFO_SOURCE, BUNDLE_INFO_SOURCE\n",
    "\"\"\"\n",
    "# Big Query Book Master\n",
    "books_info_database = \"master_dim_data\"\n",
    "books_info_table = \"books_info_source\"\n",
    "#booksinfo_df = read_bq_table(f\"button-datawarehouse.master_dim_data.testtable\", client=bq_client)\n",
    "booksinfodf = read_bq_table(f\"{project_id}.{books_info_database}.{books_info_table}\", bq_client)\n",
    "\n",
    "# Big Query Bundle Master\n",
    "bundle_info_database = \"master_dim_data\"\n",
    "bundle_info_table = \"bundle_info_source\"\n",
    "#booksinfo_df = read_bq_table(f\"button-datawarehouse.master_dim_data.testtable\", client=bq_client)\n",
    "bundleinfodf = read_bq_table(f\"{project_id}.{bundle_info_database}.{bundle_info_table}\", bq_client)\n",
    "\n",
    "# Clean Books Info Source\n",
    "\n",
    "booksinfodf['Audiobook_Royalty_Rate'] = booksinfodf['Audiobook_Royalty_Rate'].fillna('0.25')\n",
    "booksinfodf['Print_Royalty_Rate'] = booksinfodf['Print_Royalty_Rate'].fillna('0.15')\n",
    "booksinfodf['eBook_Royalty_Rate'] = booksinfodf['eBook_Royalty_Rate'].fillna('0.25')\n",
    "booksinfodf['Print_ISBN'] = booksinfodf['Print_ISBN'].fillna('NA-Print-' + booksinfodf['Short_Hand_Title'])\n",
    "booksinfodf['eBook_ISBN'] = booksinfodf['eBook_ISBN'].fillna('NA-eBook-' + booksinfodf['Short_Hand_Title'])\n",
    "booksinfodf['Audiobook_ISBN'] = booksinfodf['Audiobook_ISBN'].fillna('NA-Audiobook-' + booksinfodf['Short_Hand_Title'])\n",
    "booksinfodf['Hardcover_ISBN'] = booksinfodf['Hardcover_ISBN'].fillna('NA-Hardcover-' + booksinfodf['Short_Hand_Title'])\n",
    "booksinfodf['Number_of_Pages'] = booksinfodf['Number_of_Pages'].fillna(0)\n",
    "\n",
    "\"\"\"\n",
    "1. START WITH SCB BOOKS AND WC BOOKS CLEAN\n",
    "\"\"\"\n",
    "# Set Dtype Dict\n",
    "\n",
    "source_book_dtypes = { \"SourceTitle\" : object,\n",
    "                      \"CleanTitle\" : object,\n",
    "                      \"BookType\" :object,\n",
    "                      \"Source\" :object\n",
    "                      }\n",
    "\n",
    "# Grab from Stage, set dtypes\n",
    "scb_clean = get_bucket_csv(bucket_name, 'stage/scb_stage/SCB_Books_All.csv', dtype_spec=source_book_dtypes, client=storage_client).reset_index(drop=True).drop_duplicates()\n",
    "wc_clean = get_bucket_csv(bucket_name, 'stage/woocom_stage/WooCom_Books_All.csv', dtype_spec=source_book_dtypes, client=storage_client).reset_index(drop=True).drop_duplicates()\n",
    "# Merch & Bundle\n",
    "wc_merch = get_bucket_csv(bucket_name, 'stage/woocom_stage/WooCom_Merch_All.csv', client=storage_client).reset_index(drop=True).drop_duplicates()\n",
    "wc_bundle = get_bucket_csv(bucket_name, 'stage/woocom_stage/WooCom_Bundle_All.csv', client=storage_client).reset_index(drop=True).drop_duplicates()\n",
    "\n",
    "\"\"\"\n",
    "2. APPEND THE FRAMES TOGETHER\n",
    "\"\"\"\n",
    "wc_scb = pd.concat([wc_clean, scb_clean], ignore_index=True)\n",
    "wc_scb['key'] = 0\n",
    "booksinfodf['key'] = 0\n",
    "cross_join = booksinfodf.merge(wc_scb, on='key', how='outer')\n",
    "booksf = cross_join.copy()\n",
    "booksf = booksf.set_index('Book_Title', drop=False)\n",
    "booksf = booksf.rename(columns={'Book_Title': 'MasterTitle'})\n",
    "\n",
    "# Initial cleaning step: strip leading and trailing spaces from Master and Clean\n",
    "booksf['CleanTitle'] = booksf['CleanTitle'].apply(lambda x : x.strip())\n",
    "booksf['MasterTitle'] = booksf['MasterTitle'].fillna('')\n",
    "booksf['MasterTitle'] = booksf['MasterTitle'].apply(lambda x : x.strip())\n",
    "booksf['TestTitle'] = booksf['CleanTitle']\n",
    "\n",
    "# Word and string replacements\n",
    "words_to_replace = r'\\s+\\b(the|and)\\b\\s+|\\s*\\|\\s*'\n",
    "\n",
    "# [():] matches any single character in the set\n",
    "# The other words are matched directly\n",
    "chars_and_phrases_to_remove = r\"[():]|pre-order|pre order|paperback|hardcover|'|├│n|ΓÇ£|ΓÇ¥|out of print|digital only|[//:]|Γäó\"\n",
    "# --- MasterTitleL chained cleaning operation ---\n",
    "booksf['MasterTitleL'] = (\n",
    "    booksf['MasterTitle']\n",
    "    .str.lower()\n",
    "    .str.replace(r'[^a-zA-Z0-9\\s]', ' ', regex=True)\n",
    "    .str.replace('digital only // out of print', '', regex=True)\n",
    "    .str.replace(words_to_replace, ' ', regex=True)        # Replace ' the ', ' and ', '|' with a space\n",
    "    .str.replace(chars_and_phrases_to_remove, '', regex=True) # Remove all other unwanted text\n",
    "    .str.replace(r'\\s+', ' ', regex=True)                  # Collapse multiple spaces into one\n",
    "    .str.strip()                                           # Remove leading/trailing spaces\n",
    ")\n",
    "\n",
    "# --- TestTitleL chained cleaning operation ---\n",
    "booksf['TestTitleL'] = (\n",
    "    booksf['TestTitle']\n",
    "    .str.lower()\n",
    "    .str.replace(r'[^a-zA-Z0-9\\s]', ' ', regex=True)\n",
    "    .str.replace('digital only // out of print', '', regex=True)\n",
    "    .str.replace(words_to_replace, ' ', regex=True)        # Replace ' the ', ' and ', '|' with a space\n",
    "    .str.replace(chars_and_phrases_to_remove, '', regex=True) # Remove all other unwanted text\n",
    "    .str.replace(r'\\s+', ' ', regex=True)                  # Collapse multiple spaces into one\n",
    "    .str.strip()                                           # Remove leading/trailing spaces\n",
    ")\n",
    "\n",
    "# Specific Cleanups\n",
    "# Define a dictionary for these direct string replacements\n",
    "replacements = {\n",
    "    'future limited edition': 'future limited edition hilborn',\n",
    "    'helium limited edition': 'helium limited edition francisco',\n",
    "    'madness vase': 'madness vase gibson'\n",
    "}\n",
    "\n",
    "# Use pd.Series.replace() with the dictionary\n",
    "# regex=True is crucial to replace these substrings anywhere in the title\n",
    "booksf['TestTitleL'] = booksf['TestTitleL'].replace(replacements, regex=True)\n",
    "\n",
    "# 2. Use .loc for the conditional update\n",
    "# This is much faster than an if/else lambda\n",
    "condition = (booksf['TestTitleL'] == 'poetry by chance')\n",
    "booksf.loc[condition, 'TestTitleL'] += ' an anthology of poems powered by metaphor dice'\n",
    "\n",
    "# Strip one more time to catch any whitepaces added during cleanup\n",
    "booksf['TestTitleL'] = booksf['TestTitleL'].apply(lambda x : x.strip())\n",
    "booksf['MasterTitleL'] = booksf['MasterTitleL'].apply(lambda x : x.strip())\n",
    "\n",
    "\"\"\" \n",
    "3. FUZZY MATCH MASTER TO TEST\n",
    "\"\"\"\n",
    "booksf2 = booksf.copy()\n",
    "\n",
    "# 1. Prepare the vectorizer's vocabulary\n",
    "all_titles = pd.concat([booksf2['MasterTitleL'], booksf2['TestTitleL']]).dropna().unique()\n",
    "vectorizer = TfidfVectorizer().fit(all_titles)\n",
    "\n",
    "# 2. Create TF-IDF vectors, filling NaNs\n",
    "vectors1 = vectorizer.transform(booksf2['MasterTitleL'].fillna(''))\n",
    "vectors2 = vectorizer.transform(booksf2['TestTitleL'].fillna(''))\n",
    "\n",
    "# 3. Calculate similarity\n",
    "# Normalize the row vectors to unit length\n",
    "vectors1_normalized = normalize(vectors1)\n",
    "vectors2_normalized = normalize(vectors2)\n",
    "\n",
    "# Compute the dot product of corresponding row vectors\n",
    "# This is equivalent to cosine similarity for normalized vectors\n",
    "similarity_scores = np.asarray(vectors1_normalized.multiply(vectors2_normalized).sum(axis=1)).flatten()\n",
    "\n",
    "# 4. Add the new score to booksf2\n",
    "booksf2['TfidfSimilarity'] = similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04d077f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SourceTitle    object\n",
       "CleanTitle     object\n",
       "BookType       object\n",
       "Source         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8766faae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SourceTitle    object\n",
       "CleanTitle     object\n",
       "BookType       object\n",
       "Source         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scb_clean.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "541a8a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_path = r'D:\\BleakRiverDataServ\\Clients\\Button\\RoyaltyCheck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab7de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "frat2 = booksf2['MasterTitle'] == \"You Better Be Lightning\"\n",
    "bookfilt2 = booksf2[frat2].copy()\n",
    "bookfilt2.to_csv(r'D:\\BleakRiverDataServ\\Clients\\Button\\Notes\\bookmatch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc491d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "booksf2.to_csv(archive_path + r'\\bookmatch_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4a2c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bp_dw_gcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
